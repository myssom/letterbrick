import streamlit as st
from openai import OpenAI
from fpdf import FPDF
from PIL import Image
import pytesseract
import re, json, os
from datetime import datetime
import tempfile

# âœ… OCR ì„¤ì •
import os

# í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œëŠ” OCR êº¼ë‘ê¸°
if not os.environ.get("STREAMLIT_SERVER"):
    pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

if not os.environ.get("STREAMLIT_SERVER"):
    st.markdown("### ğŸ“¸ ì†ê¸€ì”¨ ì‚¬ì§„ ì—…ë¡œë“œ (OCR)")
    ocr_image = st.file_uploader("ğŸ‘‰ ì†ê¸€ì”¨ ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "png"])

    if ocr_image:
        try:
            img = Image.open(ocr_image)
            ocr_text = pytesseract.image_to_string(img, lang="kor")
            st.success("âœ… ì¸ì‹ ì™„ë£Œ!")
        except Exception as e:
            st.error(f"âŒ OCR ì˜¤ë¥˜: {e}")

# OpenAI ì—°ê²°
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ì €ì¥ íŒŒì¼
HISTORY_FILE = "history.json"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë‚˜ì˜ ì´ì•¼ê¸°ë¥¼ ìŒ“ëŠ” 15ë¶„", layout="centered")

# ìŠ¤íƒ€ì¼
st.markdown("""
    <style>
    body { background-color: #f0fbf9 !important; }
    html, body, [class*="css"] {
        font-size: 17px !important;
        font-family: 'Pretendard', sans-serif;
        line-height: 1.6;
        color: #2e2e2e;
    }
    h3 { font-size: 26px !important; font-weight: 600; margin-top: 1.5rem; }
    p { font-size: 18px !important; }
    </style>
""", unsafe_allow_html=True)

# ì œëª© + ë¡œê³ 
col1, col2 = st.columns([6, 2])
with col1:
    st.markdown("<h1 style='font-size: 32px;'>ë‚˜ì˜ ì´ì•¼ê¸°ë¥¼ ìŒ“ëŠ” 15ë¶„</h1>", unsafe_allow_html=True)
with col2:
    st.image("letterbrick_logo.png", width=300)

# íˆìŠ¤í† ë¦¬ ë¡œë“œ/ì €ì¥
def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_history(data):
    history = load_history()
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    history[now] = data
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# PDF ìƒì„± í•¨ìˆ˜
def generate_pdf(data: dict):
    pdf = FPDF()
    pdf.add_page()
    pdf.add_font("Nanum", "", "NanumGothic.ttf", uni=True)
    pdf.set_font("Nanum", size=12)
    pdf.set_auto_page_break(auto=True, margin=15)

    pdf.cell(0, 10, "ë ˆí„°ë¸Œë¦­ í•„ì‚¬ í‰ê°€ ë¦¬í¬íŠ¸", ln=True, align="C")
    pdf.ln(10)

    for section, content in data.items():
        pdf.set_font("Nanum", 'B', 12)
        pdf.cell(0, 10, f"â–  {section}", ln=True)
        pdf.set_font("Nanum", size=12)
        for line in content.split("\n"):
            pdf.multi_cell(0, 8, line)
        pdf.ln(5)

    tmp_path = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
    pdf.output(tmp_path.name)
    return tmp_path.name

# íˆìŠ¤í† ë¦¬ ë³´ê¸°
with st.expander("ğŸ“š ë‚˜ì˜ í•„ì‚¬ íˆìŠ¤í† ë¦¬ ë³´ê¸°"):
    history = load_history()
    if history:
        for date, item in sorted(history.items(), reverse=True):
            st.markdown(f"### ğŸ“… {date}")
            for key, value in item.items():
                st.markdown(f"**{key}**:\n\n{value}")
            st.markdown("---")
    else:
        st.info("ì•„ì§ ì €ì¥ëœ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

# âœ… OCR ì—…ë¡œë“œ
st.markdown("<h3>ğŸ“¸ ì†ê¸€ì”¨ ì‚¬ì§„ ì—…ë¡œë“œ (OCR)</h3>", unsafe_allow_html=True)
ocr_image = st.file_uploader("ğŸ‘‰ í•„ì‚¬í•œ ì†ê¸€ì”¨ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (jpg, png)", type=["jpg", "jpeg", "png"], key="ocr_upload")

ocr_text = ""
if ocr_image:
    try:
        img = Image.open(ocr_image)
        ocr_text = pytesseract.image_to_string(img, lang="kor")
        st.success("âœ… í…ìŠ¤íŠ¸ ì¸ì‹ ì™„ë£Œ!")
        st.text_area("ğŸ“ ì¸ì‹ëœ ë¬¸ì¥", value=ocr_text, height=120, disabled=True)
    except Exception as e:
        st.error(f"âŒ OCR ì˜¤ë¥˜ ë°œìƒ: {e}")

# ğŸ“ ë¬¸ì¥ í•„ì‚¬
st.markdown("<h3>ğŸ“ ì˜¤ëŠ˜ì˜ ë¬¸ì¥ í•„ì‚¬</h3>", unsafe_allow_html=True)
st.markdown("<p>ì˜¤ëŠ˜ì˜ ë¬¸ì¥ì„ ì§ì ‘ í•„ì‚¬í•´ë³´ì„¸ìš”.</p>", unsafe_allow_html=True)
original_text = st.text_area("", key="original")

if st.button("ğŸ“‹ ë¬¸ì¥ ë¶„ì„ ìš”ì²­", key="analyze_btn") and original_text:
    with st.spinner("ë¬¸ì¥ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        prompt = f"""
        ë¬¸ì˜ˆì°½ì‘ êµìˆ˜ì²˜ëŸ¼ ì•„ë˜ ë¬¸ì¥ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”.
        ê° í•­ëª©ì€ Markdown í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ê³ , ì¤‘ìš”í•œ ë‹¨ì–´ëŠ” **êµµê²Œ** í‘œì‹œí•´ ì£¼ì„¸ìš”.

        âœ… í˜•íƒœì†Œ ë¶„ì„: ë‹¨ì–´(í’ˆì‚¬) + ì¡°ì‚¬
        âœ… ì˜ë¯¸ ë¶„ì„: ì£¼ìš” ë‹¨ì–´ â†’ ì˜ë¯¸ ì„¤ëª… (í‘œ í˜•ì‹)
        âœ… ìˆ˜ì‚¬ë²• ë¶„ì„: ì–´ë–¤ ìˆ˜ì‚¬ë²•ì„ ì‚¬ìš©í–ˆê³  ì–´ë–¤ íš¨ê³¼ê°€ ìˆëŠ”ì§€ ì„¤ëª…

        ë¬¸ì¥: "{original_text}"
        """
        res = client.chat.completions.create(model="gpt-4", messages=[{"role": "user", "content": prompt}])
        st.markdown("<h3>ğŸ” ë¬¸ì¥ ë¶„ì„ ê²°ê³¼</h3>", unsafe_allow_html=True)
        st.markdown(res.choices[0].message.content)

# ğŸ”§ í˜•íƒœë³€í˜• í•„ì‚¬
st.markdown("<h3>ğŸ”§ í˜•íƒœë³€í˜• í•„ì‚¬</h3>", unsafe_allow_html=True)
st.markdown("<p>ì›ë¬¸ì˜ êµ¬ì¡°ë‚˜ ì–´ìˆœì„ ë°”ê¿” í‘œí˜„í•´ë³´ì„¸ìš”.</p>", unsafe_allow_html=True)
form1 = st.text_area("", key="form1")

if st.button("ğŸ¤– AI í”¼ë“œë°± ë°›ê¸° (í˜•íƒœë³€í˜•)", key="form1_btn"):
    with st.spinner("AIê°€ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):

        # í‰ê°€
        p1 = f"""
        ì•„ë˜ ë¬¸ì¥ì€ ì‚¬ìš©ìì˜ í˜•íƒœë³€í˜• í•„ì‚¬ì…ë‹ˆë‹¤.
        ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ ì—„ê²©í•˜ê²Œ í‰ê°€í•´ ì£¼ì„¸ìš”:
        - êµ¬ì¡°ì  ë³€í˜•ë„ (30ì )
        - ì˜ë¯¸ ë³´ì¡´ (30ì )
        - ë¬¸ë²• ì •í™•ì„± (20ì )
        - í‘œí˜„ë ¥ (20ì )

        í•­ëª©ë³„ ì ìˆ˜ + ì´ì  + ê°œì„  ì˜ˆì‹œ í¬í•¨ (Markdown í˜•ì‹)

        ë¬¸ì¥: "{form1}"
        """
        r1 = client.chat.completions.create(model="gpt-4", messages=[{"role": "user", "content": p1}])
        st.markdown("<h3>ğŸ“Š í˜•íƒœë³€í˜• í•„ì‚¬ í‰ê°€</h3>", unsafe_allow_html=True)
        st.markdown(r1.choices[0].message.content)

        # êµìˆ˜ í‰ê°€
        prof1 = f"""
        ì•„ë˜ ë¬¸ì¥ì„ **AI ë¬¸ì°½ê³¼ êµìˆ˜**ì²˜ëŸ¼ í‰ê°€í•´ ì£¼ì„¸ìš”.
        - ì‘ë²•ì ìœ¼ë¡œ í•œ ë¬¸ì¥ìœ¼ë¡œ í”¼ë“œë°±
        - ì–´ë¯¸ëŠ” ëª¨ë‘ ì¡´ëŒ“ë§(~ì…ë‹ˆë‹¤ / ~í•©ë‹ˆë‹¤ ë“±)ë¡œ í†µì¼í•´ ì£¼ì„¸ìš”.

        ë¬¸ì¥: "{form1}"
        """
        rp1 = client.chat.completions.create(model="gpt-4", messages=[{"role": "user", "content": prof1}])
        st.markdown("<h3>ğŸ“ AI ë¬¸ì°½ê³¼ êµìˆ˜ì˜ í•œ ì¤„ í‰ (í˜•íƒœë³€í˜•)</h3>", unsafe_allow_html=True)
        st.markdown(rp1.choices[0].message.content)

# ğŸ–Œï¸ ì°½ì˜ì  í•„ì‚¬
st.markdown("<h3>ğŸ–Œï¸ ì°½ì˜ì  í•„ì‚¬</h3>", unsafe_allow_html=True)
st.markdown("<p>ììœ ë¡­ê²Œ ìƒìƒë ¥ê³¼ ê°ì„±ì„ ë‹´ì•„ ì°½ì˜ì ìœ¼ë¡œ í‘œí˜„í•´ë³´ì„¸ìš”.</p>", unsafe_allow_html=True)
form2 = st.text_area("", key="form2")

if st.button("ğŸ¤– AI í”¼ë“œë°± ë°›ê¸° (ì°½ì˜ì )", key="form2_btn"):
    with st.spinner("AIê°€ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):

        # í‰ê°€
        p2 = f"""
        ì•„ë˜ ë¬¸ì¥ì€ ì‚¬ìš©ìì˜ ì°½ì˜ì  í•„ì‚¬ì…ë‹ˆë‹¤.
        ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ ì—„ê²©í•˜ê²Œ í‰ê°€í•´ ì£¼ì„¸ìš”:
        - ê°ì„± ì „ë‹¬ë ¥
        - ì°½ì˜ì„±
        - ë¬¸ì¥ ì™„ì„±ë„
        - ìŠ¤íƒ€ì¼ ì í•©ì„±

        1. ë³„ì  (ìˆ«ìë§Œ, 1~5ì )
        2. ì¥ì 
        3. ê°œì„ ì 
        4. ì´í‰

        ë³„ì ì€ ë°˜ë“œì‹œ ìˆ«ìë§Œ í‘œì‹œí•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” Markdown í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.

        ë¬¸ì¥: "{form2}"
        """
        r2 = client.chat.completions.create(model="gpt-4", messages=[{"role": "user", "content": p2}])
        full_response = r2.choices[0].message.content

        # ë³„ì  ì¶”ì¶œ (ì •í™•í•˜ê²Œ!)
        star_match = re.search(r"\b([1-5](?:\.5)?)\b", full_response)
        if star_match:
            score = float(star_match.group(1))
            fixed = round(score * 2) / 2
            full = int(fixed)
            half = 1 if fixed % 1 == 0.5 else 0
            stars = "â­ï¸" * full + "â˜†" * half
            st.markdown("<h3>ğŸ–Œï¸ ì°½ì˜ì  í•„ì‚¬ í‰ê°€</h3>", unsafe_allow_html=True)
            st.markdown(f"<p style='font-size:24px'>{stars} ({fixed}ì )</p>", unsafe_allow_html=True)

        # í”¼ë“œë°± ì „ì²´ ì¶œë ¥
        st.markdown(full_response)

        # êµìˆ˜ í‰ê°€
        prof2 = f"""
        ì•„ë˜ ë¬¸ì¥ì„ **AI ë¬¸ì°½ê³¼ êµìˆ˜**ì²˜ëŸ¼ í‰ê°€í•´ ì£¼ì„¸ìš”.
        - ì‘ë²•ì ìœ¼ë¡œ í•œ ë¬¸ì¥ìœ¼ë¡œ
        - ì–´ë¯¸ëŠ” ëª¨ë‘ **ì¡´ëŒ“ë§**(~ì…ë‹ˆë‹¤ / ~í•©ë‹ˆë‹¤)ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

        ë¬¸ì¥: "{form2}"
        """
        rp2 = client.chat.completions.create(model="gpt-4", messages=[{"role": "user", "content": prof2}])
        st.markdown("<h3>ğŸ“ AI ë¬¸ì°½ê³¼ êµìˆ˜ì˜ í•œ ì¤„ í‰ (ì°½ì˜ì  í•„ì‚¬)</h3>", unsafe_allow_html=True)
        st.markdown(rp2.choices[0].message.content)
        result = {
            "ğŸ“ ì›ë¬¸": original_text,
            "ğŸ”§ í˜•íƒœë³€í˜•": form1,
            "ğŸ–Œï¸ ì°½ì˜ì ": form2,
            "ğŸ” ë¶„ì„": analysis,
            "ğŸ“Š í˜•íƒœë³€í˜• í‰ê°€": f1_eval,
            "ğŸ“ í˜•íƒœ í•œ ì¤„ í‰": pf1_line,
            "ğŸ–Œï¸ ì°½ì˜ í‰ê°€": f2_eval,
            "ğŸ“ ì°½ì˜ í•œ ì¤„ í‰": pf2_line
        }
        save_history(result)
        st.success("ğŸ“¥ ì €ì¥ ì™„ë£Œ! íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

        pdf_file = generate_pdf(result)
        with open(pdf_file, "rb") as f:
            st.download_button(
                label="ğŸ“„ PDFë¡œ ì €ì¥í•˜ê¸°",
                data=f,
                file_name="letterbrick_report.pdf",
                mime="application/pdf"
            )
