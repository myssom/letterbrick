import streamlit as st
import openai
from fpdf import FPDF
from PIL import Image
import pytesseract
import re, json, os
from datetime import datetime
import tempfile

# âœ… OCR ì„¤ì •
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# OpenAI ì—°ê²°
openai.api_key = st.secrets["OPENAI_API_KEY"]

# ì €ì¥ íŒŒì¼
HISTORY_FILE = "history.json"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë‚˜ì˜ ì´ì•¼ê¸°ë¥¼ ìŒ“ëŠ” 15ë¶„", layout="centered")

# ìŠ¤íƒ€ì¼
st.markdown("""
    <style>
    body { background-color: #f0fbf9 !important; }
    html, body, [class*="css"] {
        font-size: 17px !important;
        font-family: 'Pretendard', sans-serif;
        line-height: 1.6;
        color: #2e2e2e;
    }
    h3 { font-size: 26px !important; font-weight: 600; margin-top: 1.5rem; }
    p { font-size: 18px !important; }
    </style>
""", unsafe_allow_html=True)

# ì œëª© + ë¡œê³ 
col1, col2 = st.columns([6, 2])
with col1:
    st.markdown("<h1 style='font-size: 32px;'>ë‚˜ì˜ ì´ì•¼ê¸°ë¥¼ ìŒ“ëŠ” 15ë¶„</h1>", unsafe_allow_html=True)
with col2:
    st.image("letterbrick_logo.png", width=300)

# íˆìŠ¤í† ë¦¬ ë¡œë“œ/ì €ì¥
def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_history(data):
    history = load_history()
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    history[now] = data
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# PDF ìƒì„± í•¨ìˆ˜
def generate_pdf(data: dict):
    pdf = FPDF()
    pdf.add_page()
    pdf.add_font("Nanum", "", "NanumGothic.ttf", uni=True)
    pdf.set_font("Nanum", size=12)
    pdf.set_auto_page_break(auto=True, margin=15)

    pdf.cell(0, 10, "ë ˆí„°ë¸Œë¦­ í•„ì‚¬ í‰ê°€ ë¦¬í¬íŠ¸", ln=True, align="C")
    pdf.ln(10)

    for section, content in data.items():
        pdf.set_font("Nanum", 'B', 12)
        pdf.cell(0, 10, f"â–  {section}", ln=True)
        pdf.set_font("Nanum", size=12)
        for line in content.split("\n"):
            pdf.multi_cell(0, 8, line)
        pdf.ln(5)

    tmp_path = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
    pdf.output(tmp_path.name)
    return tmp_path.name

# íˆìŠ¤í† ë¦¬ ë³´ê¸°
with st.expander("ğŸ“š ë‚˜ì˜ í•„ì‚¬ íˆìŠ¤í† ë¦¬ ë³´ê¸°"):
    history = load_history()
    if history:
        for date, item in sorted(history.items(), reverse=True):
            st.markdown(f"### ğŸ“… {date}")
            for key, value in item.items():
                st.markdown(f"**{key}**:\n\n{value}")
            st.markdown("---")
    else:
        st.info("ì•„ì§ ì €ì¥ëœ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

# âœ… OCR ì—…ë¡œë“œ
st.markdown("<h3>ğŸ“¸ ì†ê¸€ì”¨ ì‚¬ì§„ ì—…ë¡œë“œ (OCR)</h3>", unsafe_allow_html=True)
ocr_image = st.file_uploader("ğŸ‘‰ í•„ì‚¬í•œ ì†ê¸€ì”¨ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (jpg, png)", type=["jpg", "jpeg", "png"], key="ocr_upload")

ocr_text = ""
if ocr_image:
    try:
        img = Image.open(ocr_image)
        ocr_text = pytesseract.image_to_string(img, lang="kor")
        st.success("âœ… í…ìŠ¤íŠ¸ ì¸ì‹ ì™„ë£Œ!")
        st.text_area("ğŸ“ ì¸ì‹ëœ ë¬¸ì¥", value=ocr_text, height=120, disabled=True)
    except Exception as e:
        st.error(f"âŒ OCR ì˜¤ë¥˜ ë°œìƒ: {e}")

# ğŸ“ ë¬¸ì¥ í•„ì‚¬
st.markdown("<h3>ğŸ“ ì˜¤ëŠ˜ì˜ ë¬¸ì¥ í•„ì‚¬</h3>", unsafe_allow_html=True)
st.markdown("<p>ì˜¤ëŠ˜ì˜ ë¬¸ì¥ì„ ì§ì ‘ í•„ì‚¬í•´ë³´ì„¸ìš”.</p>", unsafe_allow_html=True)
original_text = st.text_area("", key="original")

# âœ… ì„¸ì…˜ ìƒíƒœ ì¤€ë¹„ (í˜ì´ì§€ ìƒë‹¨ì— í•œ ë²ˆë§Œ ì„ ì–¸í•´ ì£¼ì„¸ìš”)
if "analysis_result" not in st.session_state:
    st.session_state.analysis_result = None
    st.session_state.last_input = ""

# ğŸ§  ë¬¸ì¥ ë¶„ì„ ìš”ì²­ ë²„íŠ¼
if st.button("ğŸ“‹ ë¬¸ì¥ ë¶„ì„ ìš”ì²­", key="analyze_btn") and original_text:
    if st.session_state.last_input != original_text:
        with st.spinner("ë¬¸ì¥ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            prompt = f"""
ë‹¹ì‹ ì€ ë¬¸ì˜ˆì°½ì‘ê³¼ êµìˆ˜ì…ë‹ˆë‹¤.
í•™ìƒì´ í•„ì‚¬í•œ ë¬¸ì¥ì„ ì‘ë²• ê¸°ì¤€ì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ì´ ë¶„ì„í•´ ì£¼ì„¸ìš”.
**Markdown í˜•ì‹ìœ¼ë¡œ ì¶œë ¥**í•˜ê³ , **ì¤‘ìš”í•œ ë‹¨ì–´ëŠ” êµµê²Œ** í‘œì‹œí•´ ì£¼ì„¸ìš”.

---

### âœ… í˜•íƒœì†Œ ë¶„ì„
- ë‹¨ì–´(í’ˆì‚¬) + ì¡°ì‚¬ í˜•íƒœë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”. í‘œ í˜•ì‹ì´ ì¢‹ìŠµë‹ˆë‹¤.

---

### âœ… ì˜ë¯¸ ë¶„ì„
ë‹¨ìˆœí•œ ìš”ì•½ì´ ì•„ë‹ˆë¼ **ë¬¸ì¥ì˜ ìˆ¨ì€ ì£¼ì œì˜ì‹ê³¼ ê°ì •, ìƒì§•ì„±**ì„ íŒŒì•…í•´ ì£¼ì„¸ìš”.

- ì£¼ì œì˜ì‹: ...
- ì¤‘ì‹¬ ì˜ë¯¸: ...
- ê°ì •ì  ë‰˜ì•™ìŠ¤: ...
- ìƒì§• ë¶„ì„: ...

---

### âœ… ìˆ˜ì‚¬ë²• ë¶„ì„
- ì–´ë–¤ ìˆ˜ì‚¬ë²•ì´ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ ì‹ë³„í•˜ê³ ,
- ê·¸ê²ƒì´ ë¬¸ì¥ì˜ ì „ë‹¬ë ¥ì— ì–´ë–¤ íš¨ê³¼ë¥¼ ì£¼ëŠ”ì§€ í‰ê°€í•´ ì£¼ì„¸ìš”.

ë¬¸ì¥:
"{original_text}"
"""
           res = openai.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2  # ê²°ê³¼ ì•ˆì •í™”
            )
            st.session_state.analysis_result = res.choices[0].message.content
            st.session_state.last_input = original_text

# âœ… ê²°ê³¼ ì¶œë ¥
if st.session_state.analysis_result:
    st.markdown("<h3>ğŸ” ë¬¸ì¥ ë¶„ì„ ê²°ê³¼</h3>", unsafe_allow_html=True)
    st.markdown(st.session_state.analysis_result)


# ğŸ”§ í˜•íƒœë³€í˜• í•„ì‚¬
st.markdown("<h3>ğŸ”§ í˜•íƒœë³€í˜• í•„ì‚¬</h3>", unsafe_allow_html=True)
st.markdown("<p>ì›ë¬¸ì˜ êµ¬ì¡°ë‚˜ ì–´ìˆœì„ ë°”ê¿” í‘œí˜„í•´ë³´ì„¸ìš”.</p>", unsafe_allow_html=True)
form1 = st.text_area("", key="form1")

if st.button("ğŸ¤– AI í”¼ë“œë°± ë°›ê¸° (í˜•íƒœë³€í˜•)", key="form1_btn"):
    with st.spinner("AIê°€ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):

        # í‰ê°€
        p1 = f"""
        ì•„ë˜ ë¬¸ì¥ì€ ì‚¬ìš©ìì˜ í˜•íƒœë³€í˜• í•„ì‚¬ì…ë‹ˆë‹¤.
        ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ ì—„ê²©í•˜ê²Œ í‰ê°€í•´ ì£¼ì„¸ìš”:
        - êµ¬ì¡°ì  ë³€í˜•ë„ (30ì )
        - ì˜ë¯¸ ë³´ì¡´ (30ì )
        - ë¬¸ë²• ì •í™•ì„± (20ì )
        - í‘œí˜„ë ¥ (20ì )

        í•­ëª©ë³„ ì ìˆ˜ + ì´ì  + ê°œì„  ì˜ˆì‹œ í¬í•¨ (Markdown í˜•ì‹)

        ë¬¸ì¥: "{form1}"
        """
        r1 = openai.chat.completions.create(model="gpt-4", messages=[{"role": "user", "content": p1}])
        st.markdown("<h3>ğŸ“Š í˜•íƒœë³€í˜• í•„ì‚¬ í‰ê°€</h3>", unsafe_allow_html=True)
        st.markdown(r1.choices[0].message.content)

        # êµìˆ˜ í‰ê°€
        prof1 = f"""
        ì•„ë˜ ë¬¸ì¥ì„ **AI ë¬¸ì°½ê³¼ êµìˆ˜**ì²˜ëŸ¼ í‰ê°€í•´ ì£¼ì„¸ìš”.
        - ì‘ë²•ì ìœ¼ë¡œ í•œ ë¬¸ì¥ìœ¼ë¡œ í”¼ë“œë°±
        - ì–´ë¯¸ëŠ” ëª¨ë‘ ì¡´ëŒ“ë§(~ì…ë‹ˆë‹¤ / ~í•©ë‹ˆë‹¤ ë“±)ë¡œ í†µì¼í•´ ì£¼ì„¸ìš”.

        ë¬¸ì¥: "{form1}"
        """
        rp1 = openai.chat.completions.create(model="gpt-4", messages=[{"role": "user", "content": prof1}])
        st.markdown("<h3>ğŸ“ AI ë¬¸ì°½ê³¼ êµìˆ˜ì˜ í•œ ì¤„ í‰ (í˜•íƒœë³€í˜•)</h3>", unsafe_allow_html=True)
        st.markdown(rp1.choices[0].message.content)

# ğŸ–Œï¸ ì°½ì˜ì  í•„ì‚¬
st.markdown("<h3>ğŸ–Œï¸ ì°½ì˜ì  í•„ì‚¬</h3>", unsafe_allow_html=True)
st.markdown("<p>ììœ ë¡­ê²Œ ìƒìƒë ¥ê³¼ ê°ì„±ì„ ë‹´ì•„ ì°½ì˜ì ìœ¼ë¡œ í‘œí˜„í•´ë³´ì„¸ìš”.</p>", unsafe_allow_html=True)
form2 = st.text_area("", key="form2")  

if st.button("ğŸ¤– AI í”¼ë“œë°± ë°›ê¸° (ì°½ì˜ì )", key="form2_btn"):
    with st.spinner("AIê°€ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):

        # ğŸ” ë¬¸ì¥ ë¶„ì„ ë¨¼ì € ì‹¤í–‰
        analysis_prompt = f"""
        ë¬¸ì˜ˆì°½ì‘ êµìˆ˜ì²˜ëŸ¼ ì•„ë˜ ë¬¸ì¥ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”.
        ë¬¸ì¥: "{original_text}"
        """
        analysis = openai.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": analysis_prompt}]
        ).choices[0].message.content

        # ğŸ“Š í˜•íƒœë³€í˜• í‰ê°€ (ì¬ì‚¬ìš© ê°€ëŠ¥ or ìƒˆë¡œìš´ í‰ê°€ë„ ê°€ëŠ¥)
        p1 = f"""
        ì•„ë˜ ë¬¸ì¥ì€ ì‚¬ìš©ìì˜ í˜•íƒœë³€í˜• í•„ì‚¬ì…ë‹ˆë‹¤.
        í‰ê°€í•´ ì£¼ì„¸ìš”.
        ë¬¸ì¥: "{form1}"
        """
        f1_eval = openai.chat.completions.create(model="gpt-4", messages=[{"role": "user", "content": p1}]).choices[0].message.content

        # ğŸ“ í˜•íƒœë³€í˜• í•œ ì¤„ í‰
        prof1 = f"ë¬¸ì¥: {form1}"
        pf1_line = openai.chat.completions.create(model="gpt-4", messages=[{"role": "user", "content": prof1}]).choices[0].message.content

        # ğŸ–Œï¸ ì°½ì˜ì  í•„ì‚¬ í‰ê°€
        p2 = f"""
        ì•„ë˜ ë¬¸ì¥ì€ ì‚¬ìš©ìì˜ ì°½ì˜ì  í•„ì‚¬ì…ë‹ˆë‹¤.
        ë³„ì  + ì¥ì  + ê°œì„ ì  + ì´í‰ìœ¼ë¡œ í‰ê°€í•´ ì£¼ì„¸ìš”.
        ë¬¸ì¥: "{form2}"
        """
        r2 = openai.chat.completions.create(model="gpt-4", messages=[{"role": "user", "content": p2}])
        full_response = r2.choices[0].message.content

        # ë³„ì  ì¶”ì¶œ
        star_match = re.search(r"\b([1-5](?:\.5)?)\b", full_response)
        if star_match:
            score = float(star_match.group(1))
            fixed = round(score * 2) / 2
            full = int(fixed)
            half = 1 if fixed % 1 == 0.5 else 0
            stars = "â­ï¸" * full + "â˜†" * half
            st.markdown("<h3>ğŸ–Œï¸ ì°½ì˜ì  í•„ì‚¬ í‰ê°€</h3>", unsafe_allow_html=True)
            st.markdown(f"<p style='font-size:24px'>{stars} ({fixed}ì )</p>", unsafe_allow_html=True)

        st.markdown(full_response)
        f2_eval = full_response

        # ğŸ“ ì°½ì˜ì  í•œ ì¤„ í‰
        prof2 = f"ë¬¸ì¥: {form2}"
        pf2_line = openai.chat.completions.create(model="gpt-4", messages=[{"role": "user", "content": prof2}]).choices[0].message.content
        st.markdown("<h3>ğŸ“ AI ë¬¸ì°½ê³¼ êµìˆ˜ì˜ í•œ ì¤„ í‰ (ì°½ì˜ì  í•„ì‚¬)</h3>", unsafe_allow_html=True)
        st.markdown(pf2_line)

        # âœ… ì €ì¥
        result = {
            "ğŸ“ ì›ë¬¸": original_text,
            "ğŸ”§ í˜•íƒœë³€í˜•": form1,
            "ğŸ–Œï¸ ì°½ì˜ì ": form2,
            "ğŸ” ë¶„ì„": analysis,
            "ğŸ“Š í˜•íƒœë³€í˜• í‰ê°€": f1_eval,
            "ğŸ“ í˜•íƒœ í•œ ì¤„ í‰": pf1_line,
            "ğŸ–Œï¸ ì°½ì˜ í‰ê°€": f2_eval,
            "ğŸ“ ì°½ì˜ í•œ ì¤„ í‰": pf2_line
        }

        save_history(result)
        st.success("ğŸ“¥ ì €ì¥ ì™„ë£Œ! íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

    
